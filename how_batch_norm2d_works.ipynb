{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92e30795-c702-46d3-b126-0178225278ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from ml_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e670ac3e-aab6-4644-aa90-f4ac88819a7e",
   "metadata": {},
   "source": [
    "## Step 1: We will first create a batch of 2 image-like inputs containing 3 dimensions (channels) with 3 x 3 height and width. The batch shape would be [2, 3, 3, 3]\n",
    "\n",
    "## Image-like random channels are created using the torch.randint function, which takes a low value and a high value for random sampling and the size attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0343f9d4-eef5-4971-9917-1348b6442d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 5842\n",
      "torch.Size([2, 3, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  4.,  8.],\n",
       "          [ 0.,  5.,  4.],\n",
       "          [ 8.,  7.,  1.]],\n",
       "\n",
       "         [[33., 24., 24.],\n",
       "          [25., 34., 38.],\n",
       "          [30., 37., 21.]],\n",
       "\n",
       "         [[96., 91., 84.],\n",
       "          [87., 98., 91.],\n",
       "          [96., 85., 82.]]],\n",
       "\n",
       "\n",
       "        [[[ 5.,  8.,  0.],\n",
       "          [ 8.,  3.,  5.],\n",
       "          [ 5.,  3.,  4.]],\n",
       "\n",
       "         [[24., 36., 29.],\n",
       "          [25., 24., 28.],\n",
       "          [22., 33., 29.]],\n",
       "\n",
       "         [[83., 91., 81.],\n",
       "          [93., 85., 91.],\n",
       "          [96., 83., 83.]]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed( 5842 )\n",
    "\n",
    "img1_ch1 = torch.randint( 0, 9, size=(3, 3), dtype=torch.float32 )\n",
    "img1_ch2 = torch.randint( 20, 40, size=(3, 3), dtype=torch.float32 )\n",
    "img1_ch3 = torch.randint( 80, 99, size=(3, 3), dtype=torch.float32 )\n",
    "\n",
    "img1 = torch.stack( (img1_ch1, img1_ch2, img1_ch3), dim=0 )\n",
    "\n",
    "\n",
    "img2_ch1 = torch.randint( 0, 9, size=(3, 3), dtype=torch.float32 )\n",
    "img2_ch2 = torch.randint( 20, 40, size=(3, 3), dtype=torch.float32 )\n",
    "img2_ch3 = torch.randint( 80, 99, size=(3, 3), dtype=torch.float32 )\n",
    "\n",
    "img2 = torch.stack( (img2_ch1, img2_ch2, img2_ch3), dim=0 )\n",
    "\n",
    "batch = torch.stack( (img1, img2), dim=0 )\n",
    "\n",
    "print( batch.shape )\n",
    "\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9e8935-0356-4a54-9675-3631561628d3",
   "metadata": {},
   "source": [
    "## Step 2: We will compute the 2d Batch Normalization manually using the below formula:\n",
    "\n",
    "<div style=\"background-color:white\">\n",
    "    <img src=\"./imgs/normalization_formula.png\" />\n",
    "</div>\n",
    "\n",
    "## While γ and β are the learnable scale and shift parameters, we will use γ=1 and β=0 values, which are also the default values for the Batch Norm2D. Also, we will use ϵ = 0.00001, which is a default value for Batch Norm2D\n",
    "\n",
    "## The tensor 'mean' function is used to compute the mean of the values of each 'channel' dimension across the entire batch, as shown below. Likewise, the tensor 'var' function is used to compute the variance of the values of each 'channel' dimension across the entire batch, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b61d3018-ea24-460e-b373-bb81117f6bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Evaluated Mean: torch.Size([3])\n",
      "\n",
      "Evaluated Mean:\n",
      " tensor([ 4.3333, 28.6667, 88.6667])\n",
      "Shape of Evaluated Variance: torch.Size([3])\n",
      "\n",
      "Evaluated Variance:\n",
      " tensor([ 7.4444, 27.5556, 30.0000])\n"
     ]
    }
   ],
   "source": [
    "epsilon=1e-05\n",
    "\n",
    "'''\n",
    "The tensor 'mean' function is used to compute the mean of the values of each 'channel' dimension across the entire batch, as shown below.\n",
    "'''\n",
    "mean = batch.mean( [0,2,3] )\n",
    "\n",
    "\n",
    "'''\n",
    "The tensor 'var' function is used to compute the variance of the values of each 'channel' dimension across the entire batch, as shown below.\n",
    "'''\n",
    "var = batch.var( [0,2,3], unbiased=False )\n",
    "\n",
    "\n",
    "'''\n",
    "Note that shape of the evaluated mean and var as shown below\n",
    "'''\n",
    "\n",
    "print( \"Shape of Evaluated Mean: {}\\n\".format( mean.shape ) )\n",
    "print( \"Evaluated Mean:\\n {}\".format( mean ) )\n",
    "\n",
    "print( \"Shape of Evaluated Variance: {}\\n\".format( var.shape ) )\n",
    "print( \"Evaluated Variance:\\n {}\".format( var ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33795283-2bf5-4656-ae14-48ffc4f9b3bd",
   "metadata": {},
   "source": [
    "## Step 3: The evaluated mean and variance tensors will have to be reshaped so that they can be used in element-wise computations, as in the normalization formula above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9870797c-9aa8-433a-bd1f-bfec3f777dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Reshaped Mean: torch.Size([1, 3, 1, 1])\n",
      "\n",
      "Reshaped Mean:\n",
      "\n",
      " tensor([[[[ 4.3333]],\n",
      "\n",
      "         [[28.6667]],\n",
      "\n",
      "         [[88.6667]]]])\n",
      "\n",
      "\n",
      "####################################\n",
      "\n",
      "Shape of Reshaped Variance: torch.Size([1, 3, 1, 1])\n",
      "\n",
      "Reshaped Variance:\n",
      "\n",
      " tensor([[[[ 7.4444]],\n",
      "\n",
      "         [[27.5556]],\n",
      "\n",
      "         [[30.0000]]]])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "We will reshape the mean and variance tensors so that they can be used in element-wise computations, as in the normalization formula above.\n",
    "'''\n",
    "reshaped_mean =  mean[None, :, None, None]\n",
    "reshaped_var = var[None, :, None, None] \n",
    "\n",
    "print( \"Shape of Reshaped Mean: {}\\n\".format( reshaped_mean.shape ) )\n",
    "print( \"Reshaped Mean:\\n\\n {}\\n\".format( reshaped_mean ) )\n",
    "print( \"\\n####################################\\n\" )\n",
    "print( \"Shape of Reshaped Variance: {}\\n\".format( reshaped_var.shape ) )\n",
    "print( \"Reshaped Variance:\\n\\n {}\".format( reshaped_var ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fefa4aa-0dbe-40c8-9435-e3df9bd9ff8c",
   "metadata": {},
   "source": [
    "## Step 4: We will normalize the batch manually by evaluating the formula.\n",
    "\n",
    "## Note that broadcasting of the values will be automatically applied when element-wise computations are carried out when any corresponding dimensions, such as height and width, do not match.\n",
    "\n",
    "## γ=1 and β=0 values are used in the manually evaluated formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebd035e4-2be0-434b-b652-79f3ff5e9802",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Note that broadcasting of the values will be automatically applied when element-wise computations are carried out, when any corresponding dimensions such as height and width do not match.\n",
    "\n",
    "Note that γ=1 and β=0 values are used in the below formula.\n",
    "'''\n",
    "\n",
    "manually_normalized = ( batch - reshaped_mean ) / (torch.sqrt( reshaped_var + epsilon ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc985f47-50b2-4fe8-8db4-f0384a547651",
   "metadata": {},
   "source": [
    "## Manually normalized batch of input tensors must match the tensors normalized by batch normalization 2D module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7428d39f-58ba-478f-8364-67192d1bd345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually Normalized Batch:\n",
      "\n",
      " tensor([[[[-1.5882, -0.1222,  1.3439],\n",
      "          [-1.5882,  0.2443, -0.1222],\n",
      "          [ 1.3439,  0.9774, -1.2217]],\n",
      "\n",
      "         [[ 0.8255, -0.8890, -0.8890],\n",
      "          [-0.6985,  1.0160,  1.7780],\n",
      "          [ 0.2540,  1.5875, -1.4605]],\n",
      "\n",
      "         [[ 1.3389,  0.4260, -0.8520],\n",
      "          [-0.3043,  1.7040,  0.4260],\n",
      "          [ 1.3389, -0.6694, -1.2172]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2443,  1.3439, -1.5882],\n",
      "          [ 1.3439, -0.4887,  0.2443],\n",
      "          [ 0.2443, -0.4887, -0.1222]],\n",
      "\n",
      "         [[-0.8890,  1.3970,  0.0635],\n",
      "          [-0.6985, -0.8890, -0.1270],\n",
      "          [-1.2700,  0.8255,  0.0635]],\n",
      "\n",
      "         [[-1.0346,  0.4260, -1.3997],\n",
      "          [ 0.7912, -0.6694,  0.4260],\n",
      "          [ 1.3389, -1.0346, -1.0346]]]])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Manually normalized batch of input tensors must match the tensors normalized by batch normalization 2D module.\n",
    "'''\n",
    "\n",
    "print( \"Manually Normalized Batch:\\n\\n {}\".format( manually_normalized ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e059210-e280-49b4-aaff-29507aa41783",
   "metadata": {},
   "source": [
    "## Step 5: An instance of the PyTorch Batch Norm 2D module will be used to normalize the input batch.\n",
    "\n",
    "## An instance of the Batch Norm 2D module is created as below by indicating that the input batch has 3 channel dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e10f0592-bd99-41e9-8702-8f98c7f0b1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "An instance of the Batch Norm 2D module is created as below by indicating that the input batch has 3 channel dimensions. In addition, the 'affine' boolean property is set to False \n",
    "to indicate that the scale and shift parameters need not be applied for this simple example case. Batch Norm 2D module by default applied the scale and shift parameters which are updated during training.\n",
    "'''\n",
    "bnorm2d = nn.BatchNorm2d( 3 ) \n",
    "\n",
    "'''\n",
    "Batches of inputs are then normalized by the module instance as follows.\n",
    "'''\n",
    "bn_model_normalized = bnorm2d( batch )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ea25bd-1701-4371-9e11-707a6d9d8a6f",
   "metadata": {},
   "source": [
    "## Step 6: Compare the manually normalized and module normalized batches of inputs to verify that normalized tensor values match.\n",
    "\n",
    "## As can be seen from the display of the normalized batches, both manually normalized and module-normalized batches of input tensors match in values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afa5ec4e-8386-4db9-90b2-0c1c700cb4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module Normalized Batch:\n",
      "\n",
      " tensor([[[[-1.5882, -0.1222,  1.3439],\n",
      "          [-1.5882,  0.2443, -0.1222],\n",
      "          [ 1.3439,  0.9774, -1.2217]],\n",
      "\n",
      "         [[ 0.8255, -0.8890, -0.8890],\n",
      "          [-0.6985,  1.0160,  1.7780],\n",
      "          [ 0.2540,  1.5875, -1.4605]],\n",
      "\n",
      "         [[ 1.3389,  0.4260, -0.8520],\n",
      "          [-0.3043,  1.7040,  0.4260],\n",
      "          [ 1.3389, -0.6694, -1.2172]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2443,  1.3439, -1.5882],\n",
      "          [ 1.3439, -0.4887,  0.2443],\n",
      "          [ 0.2443, -0.4887, -0.1222]],\n",
      "\n",
      "         [[-0.8890,  1.3970,  0.0635],\n",
      "          [-0.6985, -0.8890, -0.1270],\n",
      "          [-1.2700,  0.8255,  0.0635]],\n",
      "\n",
      "         [[-1.0346,  0.4260, -1.3997],\n",
      "          [ 0.7912, -0.6694,  0.4260],\n",
      "          [ 1.3389, -1.0346, -1.0346]]]], grad_fn=<NativeBatchNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Note that both manually normalized and module-normalized batches of input tensors match in values.  \n",
    "'''\n",
    "\n",
    "print( \"Module Normalized Batch:\\n\\n {}\".format( bn_model_normalized ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca550de4-6620-483b-a7af-bc5c6ce95681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: Both manually normalized and module normalized batches match in values\n"
     ]
    }
   ],
   "source": [
    "if torch.allclose( manually_normalized, bn_model_normalized ):\n",
    "    print( \"SUCCESS: Both manually normalized and module normalized batches match in values\" )\n",
    "else:\n",
    "    raise Exception(\"ERROR: Manually normalized and module normalized batches DO NOT match in values\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76c5db3-1367-496b-9135-f6a268e6a225",
   "metadata": {},
   "source": [
    "## Step 7: Verify that the mean and standard deviation of each channel in the normalized batch are zero and one, respectively\n",
    "\n",
    "## ( Mean and Standard Deviation are expected to be very close to 0 and 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fd1461a-adc9-4c39-9fa4-2d5959d3fd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Batch Channel 1 Mean: -2.6490953430879927e-08\n",
      "\n",
      "Normalized Batch Channel 1 Std Deviation: 1.0289908647537231\n",
      "\n",
      "\n",
      "####################################\n",
      "\n",
      "Normalized Batch Channel 2 Mean: 1.8543667579251633e-07\n",
      "\n",
      "Normalized Batch Channel 2 Std Deviation: 1.0289913415908813\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print( \"Normalized Batch Channel 1 Mean: {}\\n\".format( torch.mean( bn_model_normalized[ :, 0, :, : ] ) ) )\n",
    "print( \"Normalized Batch Channel 1 Std Deviation: {}\\n\".format( torch.std( bn_model_normalized[ :, 0, :, : ] ) ) )\n",
    "print( \"\\n####################################\\n\" )\n",
    "print( \"Normalized Batch Channel 2 Mean: {}\\n\".format( torch.mean( bn_model_normalized[ :, 1, :, : ] ) ) )\n",
    "print( \"Normalized Batch Channel 2 Std Deviation: {}\\n\".format( torch.std( bn_model_normalized[ :, 1, :, : ] ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "add936a0-7b46-4144-94ea-51367e5e8ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4333, 2.8667, 8.8667])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnorm2d.running_mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
